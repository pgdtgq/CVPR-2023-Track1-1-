
# 对本次比赛中一些关键技术的说明

## 模型总体构架

1、整体采用常用的单底座（backbone），多任务头的设计。
2、backbone尝试了InternImage系列，主要尝试了 InternImage-Base 和 InternImage-XL 这两个backbone。
3、检测任务头采用DINO。
4、分割任务头采用Mask2Former。
5、对于分类任务头，采用带shortcut的MLP，即对backbone最后一层特征用GAP，之后经过MLP，在和GAP特征做shortcut add。

## 主要技术创新

1、观察到det, seg, cls三个任务在训练的时候回传给backbone的梯度的norm差异非常大。如果这时做原始的整体的 grad-clip(max_norm = 0.1, norm_type = 2) 的话，会造成整个 backbone 的特征提取偏向梯度范数最大的norm。
2、由此提出 **task-independent bakbone oriented grad clip**: 分开对三个任务的梯度分别做 grad clip，同时，对单个任务 grad clip 的结果以backbone上的梯度范数为基准，把backbone上的梯度线范数性缩放到0.1，保证三个任务在更新backbone参数的时候使用完全一样的梯度范数。

**效果**：
1、使用 task-independent bakbone oriented grad clip 后，其他设置完全不修改，分类精度从 89.05% -> 92.998%。
2、使用 task-independent bakbone oriented grad clip 后，其他设置完全不修改，分割精度从 58.851% -> 60.168%。
3、检测精度完全不变，甚至略微提升。
4、在之后的优化中，对任何一个单个任务的修改，都不会影响另外两个任务。即单个任务指标提升，其他两个任务的指标完全不受到影响。

## 其他设置

1、对分类任务使用 dynamic margin arcface, 分类精度 92.998% -> 95.2% (InternImage-Base)。

## 数据增强策略介绍

**det**
1、大分辨率基准，scale(1280, 1526), 由于 track1 A 榜长宽比固定，相当于就是(1280, 1280)，设置1526主要为了防止B榜出现长宽比不固定的情况。
2、设计双支路的数据增强:
支路A: Mosaic + mixup + colorjitter + 随机噪音
支路B: Multiscale + Autoaugment + 随机噪音
组合RandomChoice分别以0.8, 0.2的概率使用。

**seg**
0、整体思想: 无论分辨率多少，长宽比多少，都把短边resize到1024，之后使用滑窗预测。
1、设计双支路的数据增强：
支路A: Mosaic + RandomCrop(1024, 1024) + colorjitter + 随机噪音
支路B: 以1024为中心的multiscale + RandomCrop(1024, 1024) + 随机天气增强 + 小角度随机旋转 + 随机噪音

**cls**
Resize(512, 512) -> RRC(0.98, 1.0) -> 随机擦除 -> AutoAugment -> 仿射变换透视变换 -> 随机噪音

## 训练设置
1、AdamW, lr0.0002, 5个epoch做warmup, det-batchsize-per-gpu = 1, seg-batchsize-per-gpu = 2, cls-batchsize-per-gpu = 8。
2、使用IterBasedRunner。
3、设置单个epoch的iter数量 = max(det-img-num // det-batchsize + 1, seg-img-num // seg-batchsize + 1, cls-img-num // cls-batchsize + 1)
4、训练160ep。整体iter数量= 3中的单个ep数量 * 160。
5、使用cos学习率，warmup_start_ratio = 0.001, lr_schedule_end_ratio = 0.001。
